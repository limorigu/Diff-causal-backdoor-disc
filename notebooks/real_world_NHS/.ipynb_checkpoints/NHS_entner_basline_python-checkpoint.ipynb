{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import comb\n",
    "from scipy.stats import norm\n",
    "import pickle\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code inspired by makeDecisionAndEstimateEffect_3classes.m AND \n",
    "#   calculateEstimatedEffect.m\n",
    "# INPUT\n",
    "# data\n",
    "# D (n,d+3)... data matrix\n",
    "#   (n,d)  ... Z covariates\n",
    "#   (n,)   ... W auxiliary variable\n",
    "#   (n,)   ... X treatment\n",
    "#   (n,)   ... Y outcome\n",
    "# datatype ... string: 'continuous' if data are Gaussain\n",
    "#                      'discrete' if data are discrete\n",
    "# p_vals_wy_zx ... p-values from tests\n",
    "# p_vals_wy_z  ... p-values from tests\n",
    "# Zsels  ... selected Zs\n",
    "#\n",
    "# OUTPUT\n",
    "# est ... estiamte of the causal effect of x on y, or NaN\n",
    "# Dec ... decision: 1 for D1, 2 for D2, 3 for D3, 4 if Decision from Naive\n",
    "#         Bayes classifier was D1, but estimates were not similar enough, so\n",
    "#         we do not give an estimate of the causal effect of x on y, i.e. est\n",
    "#         is the following depending on Dec:\n",
    "#         if Decision is D1 (i.e. Dec=1) est is the estimate of the non-zero\n",
    "#         effect of x on y. For D2 (i.e. Dec=2), est = 0; For D3 (i.e.\n",
    "#         Dec=3), or Dec=4, est = NaN;\n",
    "# post_prob = class posterior probabilities of D1, D2, and D3 (in this order)\n",
    "def estimate_effects(D, datatype, p_vals_wy_zx, p_vals_wy_z, Zsels):\n",
    "\n",
    "    (n,d3) = D.shape\n",
    "    ixY    = d3-1\n",
    "    ixX    = d3-2\n",
    "    ixW    = d3-3\n",
    "    ixZ    = np.arange(d3-3)\n",
    "    d      = d3-3\n",
    "    t      = p_vals_wy_zx.shape[0]\n",
    "    p_reject = 0.001\n",
    "    p_accept = 0.1\n",
    "    # if datatype == 'continuous':\n",
    "    # \t# assuming n >= 5000\n",
    "    # \tp_reject = 0.001\n",
    "    # \tp_accept = 0.1\n",
    "    # elif datatype == 'discrete':\n",
    "    # \titest = 'logOdds'\n",
    "    # \tcov = D\n",
    "    # else:\n",
    "    # \terror('no such datatype')\n",
    "\n",
    "    # NOTE: we do not use this code as it is only to check if R1 or R2/R3 \n",
    "    #       applies (we assume R3 applies) \n",
    "    # getCountsFromPvalues.m\n",
    "    # ----------------------\n",
    "    # cntR3 = sum( temp{3}(:,2) > p_accept & temp{3}(:,3) < p_reject)\n",
    "    # cntR3 = np.sum(p_vals_wy_zx > p_accept & p_vals_wy_z < p_reject)\n",
    "    # cntR3_norm = cntR3/t\n",
    "\n",
    "    # calculateEstimatedEffect.m\n",
    "    # --------------------------\n",
    "    #bool = temp(:,2) > p_accept & temp(:,3) < p_reject\n",
    "    bool = np.logical_and((p_vals_wy_zx > p_accept),(p_vals_wy_z < p_reject))\n",
    "    Zaccept = np.array(Zsels)[bool]\n",
    "    times = Zaccept.shape[0]\n",
    "\n",
    "    if datatype == 'continuous':\n",
    "        b = np.ones((n,1))\n",
    "        Dx = D[:,ixX].reshape((n,1))\n",
    "        Dy = D[:,ixY].reshape((n,1))\n",
    "        if times == 0:\n",
    "            X = np.concatenate((b, Dx), axis=1)\n",
    "            C = np.dot(X.transpose(), X)\n",
    "            Xy= np.dot(X.transpose(), Dy)\n",
    "            theta = np.linalg.solve(C, Xy)\n",
    "            ate = theta[1]\n",
    "        else:\n",
    "            ate = np.zeros((times,))\n",
    "            for i in range(times):\n",
    "                Z = Zaccept[i]\n",
    "                if Z.shape[0] == 0:\n",
    "                    X = np.concatenate((b, Dx), axis=1)\n",
    "                else:\n",
    "                    X = np.concatenate((b, Dx, D[:,Z]), axis=1)\n",
    "                    # (X'X)^-1(X'y)\n",
    "                C = np.dot(X.transpose(), X)\n",
    "                Xy= np.dot(X.transpose(), Dy)\n",
    "                theta = np.linalg.solve(C, Xy)\n",
    "                # NOTE: we do not check if estimates are similar\n",
    "                #\t\tand output NaN if so, as in the original\n",
    "                #       code via:\n",
    "                # val = areEstiamtesSimilar_Clusters(ests, CIs);\n",
    "                ate[i] = theta[1]\n",
    "    elif datatype == 'discrete':\n",
    "        error('not implemented')\n",
    "    else:\n",
    "        error('no such datatype')\n",
    "\n",
    "    return ate\n",
    "\n",
    "\n",
    "# code inspired by algorithm_applyRules123_random.m\n",
    "# NOTE from entner!\n",
    "# NOTE: in the comments of the code, the rule numbers do not match the ones in\n",
    "  # the paper. (We changed themw later on in the article, apologies for any \n",
    "  # inconveniences.) Here is the correspondence between the rules:\n",
    "\n",
    "  # article               code\n",
    "  # R1 (i) + (ii)         R3 (iii) + (ii) (Note R3(i) in code is not used)\n",
    "  # R2 (i)                R1\n",
    "  # R2 (ii) + (iii)       R2\n",
    "# INPUT\n",
    "# data\n",
    "# D (n,d+3)... data matrix\n",
    "#   (n,d)  ... Z covariates\n",
    "#   (n,)   ... W auxiliary variable\n",
    "#   (n,)   ... X treatment\n",
    "#   (n,)   ... Y outcome\n",
    "# datatype ... string: 'continuous' if data are Gaussain\n",
    "#                      'discrete' if data are discrete\n",
    "# k        ... maximal size of conditioning set in independence test\n",
    "# t        ... how many tests are performed, i.e. how often do we\n",
    "#                     select a random set Z (and w) and perform test\n",
    "# \n",
    "# OUTPUT\n",
    "# p_vals ... p-values from tests\n",
    "# Zsels  ... selected Zs\n",
    "def Zsel_highdim(D, datatype, k, t):\n",
    "\n",
    "    (n,d3) = D.shape\n",
    "    ixY    = d3-1\n",
    "    ixX    = d3-2\n",
    "    ixW    = d3-3\n",
    "    ixZ    = np.arange(d3-3)\n",
    "    d      = d3-3\n",
    "\n",
    "    if datatype == 'continuous':\n",
    "        itest = 'partialCorr'\n",
    "        cov = np.cov(D.transpose())\n",
    "    elif datatype == 'discrete':\n",
    "        itest = 'logOdds'\n",
    "        cov = D\n",
    "    else:\n",
    "        error('no such datatype')\n",
    "\n",
    "    n_R3_cardZ = np.zeros((k+1,1)) # how many sets of each conditioning size up to K\n",
    "    for i in range(k+1):\n",
    "        n_R3_cardZ[i] = comb(d,i)\n",
    "\n",
    "    # cumulative proportions of conditioing sets of size 0,...,K, for one w\n",
    "    cumprop_R3 =  np.cumsum(n_R3_cardZ) / np.sum(n_R3_cardZ); \n",
    "\n",
    "\n",
    "    # save things\n",
    "    Zsels = []\n",
    "    p_vals_wy_zx = np.zeros((t,))\n",
    "    p_vals_wy_z  = np.zeros((t,))\n",
    "\n",
    "    rand_r = np.random.random(size=t)\n",
    "    for i in range(t):\n",
    "        #w = rand_d[i]\n",
    "        r   = rand_r[i]\n",
    "        cardZ = np.argmin(cumprop_R3 < r) # find the sampled bin\n",
    "        #Ww = np.setdiff1d(W,w)\n",
    "        temp = np.random.permutation(d)\n",
    "        ix_Zsel = np.sort(temp[:cardZ])\n",
    "\n",
    "        # condition 2 of R3: w indep y given Z and x\n",
    "        pval_wy_ZX_R3 = indepTest(ixW, ixY, np.append(ix_Zsel,ixX), n, cov, itest);\n",
    "\n",
    "        # condition 3 of R3: w not indep y given Z\n",
    "        pval_wy_Z_R3 = indepTest(ixW, ixY, ix_Zsel, n, cov, itest);\n",
    "\n",
    "        p_vals_wy_zx[i] = pval_wy_ZX_R3\n",
    "        p_vals_wy_z[i]  = pval_wy_Z_R3\n",
    "        Zsels.append(ix_Zsel)\n",
    "    return p_vals_wy_zx, p_vals_wy_z, Zsels\n",
    "\n",
    "\n",
    "\n",
    "def indepTest(ixA, ixB, ixZ, n, C, itest):\n",
    "    if itest == 'partialCorr':\n",
    "        ixAB = np.array([ixA,ixB])\n",
    "        #        C(indAB,indAB) - C(indAB,ixZ) * C(ixZ,ixZ)^(-1) * C(ixZ,indAB)\n",
    "        C_cond = C[ixAB,:][:,ixAB] - np.dot(C[ixAB,:][:,ixZ], np.linalg.solve(C[ixZ,:][:,ixZ], C[ixZ,:][:,ixAB]))\n",
    "        # test if partial correlation is statistically significantly different\n",
    "        # from 0 (using Fisher's Z, see Spirtes et al. p.94); if not, independence\n",
    "        r = C_cond[0,1]\n",
    "        fisherZ = 0.5* np.sqrt(n - ixZ.shape[0] - 3) * np.log(np.abs(1+r) / np.abs(1-r));\n",
    "        p = 2*(1-norm.cdf(np.abs(fisherZ)));\n",
    "    elif itest == 'logOdds':\n",
    "        error('not implemented yet')\n",
    "        #[pval_g, pval_chi] = gsquare_test(DataCov,states,w,x,Z);\n",
    "        #p = pval_g;\n",
    "    return p\n",
    "\n",
    "    # NOTE: DON'T USE THIS, JUST FOR TESTING\n",
    "def depricated_sampling(n):\n",
    "    z_dim = 30\n",
    "    u_dim = 30\n",
    "    a,b,c,d,e,l = np.random.normal(0,1,6)\n",
    "    f,g,h,j,k = np.random.normal(0,1,size=(5,z_dim))\n",
    "\n",
    "    D = np.zeros((n,z_dim*4+3))\n",
    "    for i in range(n):\n",
    "        W  = np.random.normal(0,1)\n",
    "        U1 = np.random.normal(0,1,u_dim)\n",
    "        U2 = np.random.normal(0,1,u_dim)\n",
    "        Z1 = a*U1 + b*U2 + c*W + np.random.normal(0,.5,z_dim)\n",
    "        Z2 = d*W  + np.random.normal(0,.5,z_dim)\n",
    "        Z3 = np.random.normal(0,1,z_dim)\n",
    "        Z4 = np.random.normal(0,1,z_dim)\n",
    "        X = e*W + np.dot(f,U1) + np.dot(g,Z2) + np.dot(h,Z3) + np.random.normal(0,.5)\n",
    "        Y = np.dot(j,Z3) + np.dot(k,Z4) + l*X + np.random.normal(0,.5)\n",
    "        D[i,:z_dim] = Z1\n",
    "        D[i,z_dim:z_dim*2] = Z2\n",
    "        D[i,z_dim*2:z_dim*3] = Z3\n",
    "        D[i,z_dim*3:z_dim*4] = Z4\n",
    "        D[i,z_dim*4] = W\n",
    "        D[i,z_dim*4+1] = X\n",
    "        D[i,z_dim*4+2] = Y\n",
    "    return D, l\n",
    "\n",
    "\n",
    "def run(D):\n",
    "    datatype = 'continuous' # they only have code for continuous data\n",
    "    k = 30   # maximal size of conditioning set (Z3 is true set)\n",
    "    t = 1000 # tests\n",
    "    p_vals_wy_zx, p_vals_wy_z, Zsels = Zsel_highdim(D, datatype, k, t)\n",
    "    ate = estimate_effects(D, datatype, p_vals_wy_zx, p_vals_wy_z, Zsels)\n",
    "#     print(\"ate:\")\n",
    "#     print(ate)\n",
    "    return ate, np.median(ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.734941979473452"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset in\n",
    "dat_small_var = np.array(pd.read_csv(\"../../code/real_world_nhs_dataset/nhs_data_smaller_var.csv\"))\n",
    "\n",
    "# compute Entner baseline for NHS dataset\n",
    "split = len(dat_small_var)//3\n",
    "dat_train = dat_small_var[:split]\n",
    "dat_valid = dat_small_var[split+1:]\n",
    "dat_test = dat_small_var[split*2+1:]\n",
    "\n",
    "ate_all_train, ate_median_train = run(dat_train);\n",
    "ate_all_valid, ate_median_valid = run(dat_valid);\n",
    "ate_all_test, ate_median_test = run(dat_test);\n",
    "\n",
    "ate_median_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where Entner baseline value is taken from in Table 1. **ATE_median_test~=-0.734.** Note: No seeding on Entner algo above. Some minor fluctuations possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
