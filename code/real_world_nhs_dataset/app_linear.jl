#!/Applications/Julia-1.1.app/Contents/Resources/julia/bin/julia
################################################################################
## app_linear.jl
##
## This file contains the basic functions to two primary tasls:
##
## 1. The assessment of how hard are some synthetic problems generated by
##    particular configurations. Start from function
##    `demo_linear_simulate_evaluate()`
## 2. To assess methods for linear modeling. Start from function
##    `demo_linear_simulate_learn_evaluate()`
################################################################################

using ProgressMeter, Printf
using LinearAlgebra
using StatsBase
using Statistics
using TexTables
using DataFrames, Gadfly, Compose
using PyCall
@pyimport pickle

include("simulate.jl")
include("learn_linear.jl")
include("util.jl")

################################################################################
################################################################################
## DATA STRUCTURES
## Data structures

mutable struct RmvDiagnosts # data sructure to contain all results of diagnostic runs
  
  initial_corr_px::Vector{Float64} # abs \rho(W,Y|\phi,X) pre-optimization
  final_corr_px::Vector{Float64} # abs \rho(W,Y|\phi,X) post-optimization

  initial_corr_px_rmvZ1::Vector{Float64} # abs \rho(W,Y|\phi,X) pre-optimization when removing z1
  final_corr_px_rmvZ1::Vector{Float64} # abs \rho(W,Y|\phi,X) post-optimization when removing z1

  initial_corr_px_rmvZ3::Vector{Float64} # abs \rho(W,Y|\phi,X) pre-optimization when removing z3
  final_corr_px_rmvZ3::Vector{Float64} # abs \rho(W,Y|\phi,X) post-optimization when removing z3

  initial_corr_px_rmvZ1Z2::Vector{Float64} # abs \rho(W,Y|\phi,X) pre-optimization when removing z1, z2
  final_corr_px_rmvZ1Z2::Vector{Float64} # abs \rho(W,Y|\phi,X) post-optimization when removing z1, z2

  initial_corr_px_rmvZ2Z3::Vector{Float64} # abs \rho(W,Y|\phi,X) pre-optimization when removing z2, z3
  final_corr_px_rmvZ2Z3::Vector{Float64} # abs \rho(W,Y|\phi,X) post-optimization when removing z2, z3

  initial_diff_rmvZ1_rmvZ3::Vector{Float64} # abs(\rho(W,Y|\phi(rmvz3,X)) - abs(\rho(W,Y|\phi(rmvz1,X)) 
                            # pre-optimization
  final_diff_rmvZ1_rmvZ3::Vector{Float64} # abs(\rho(W,Y|\phi(rmvz3,X)) - abs(\rho(W,Y|\phi(rmvz1,X)) 
                            # post-optimization

  initial_diff_rmvZ1Z2_rmvZ2Z3::Vector{Float64} # abs(\rho(W,Y|\phi(rmvZ2Z3,X)) - abs(\rho(W,Y|\phi(rmvZ1Z2,X)) 
                            # post-optimization
  final_diff_rmvZ1Z2_rmvZ2Z3::Vector{Float64} # abs(\rho(W,Y|\phi(rmvZ2Z3,X)) - abs(\rho(W,Y|\phi(rmvZ1Z2,X)) 
                            # post-optimization

end

################ 1. EVALUATION OF HARDNESS OF SIMULATIONS

"""
    linear_simulate_evaluate(n, p, use_population;
                             min_noise, max_noise, pseudo_pcount,
                             x_noise, y_noise,
                             prob_flip, w_effect, x_effect)
Run a simulation using sample size `n` and number of vertices given by vector
`p`, followed by an evaluation of baselines applied to this problem. If
`use_population` is `true`, this uses the model covariance matrix directly.
Error variances for each vertex is set according to the formula
`min(max_noise, max(min_noise, (pseudo_pcount - num_parents) / pseudo_pcount))`,
where `num_parents` is the number of total parents of that vertex. That is,
`pseudo_pcount` represents a number of pseudo "parents" of a vertex,
explicitly represented in the causal graph (as a node) or not (added to the
error term contribution). As the number of explicit parents in the graph
increases, the error variance decreases. It is still forced to lie on the
interval `[min_noise, max_noise]`. The exceptions are the treatment variable,
where the error variance is set to `x_noise`, and the outcome variable, where
the error variance is set to `y_noise`. This is in order to better control the
difficulty of the problem: the lower `x_noise` is, for instance, the harder the
problem becomes for the estimator that conditions on all variables.
Coefficients are sampled independently and normalized so that each variable has
variance `1`. Two coefficients are set manually: the coefficient of instrument
on treatment is set by `w_effect`, while the coefficient of treatment on
outcome is set to `x_effect`. Finally, to avoid confounding adding to up
to very small values due to averaging effects (which are more likely as the
entries of `p` grow), each vertex has causal effects on its children all drawn
with the same signal (which can be either positive or negative with equal
probability). Some variability is added by flipping the sign of each edge with
probability `prob_flip`. The closer to `0.5` this is, the higher the probability
that confounding and collider effects will be close to zero, so set it to a
small number in order to make problems harder.
This function returns matrix `B` of coefficients, covariance matrix `Omega` of
error terms, adjacency matrix `G` encoding a DAG, dataset `dat` of sample
size `n`, and a data structure `vertex_labels` indicating which type of
variable (covariates `z1`, `z2`, `z3`, `z4`, latent variables `u1` and `u2`,
instrument `w`, treatment `x` and outcome `y`) corresponds to which entry.
This function also returns four types of baselines: the consistent estimator
`ATE_right` (which is the true causal effect is `use_population == true`) that
uses the minimal adjustment set `z3`; `ATE_all_z`, the inconsistent estimator
that uses all covariates; `ATE_OK_z`, another consistent estimator that uses
an unnecessarily large covariate set; and `ATE_margin`, the inconsistent
estimator that ignores any covariate adjustment.
"""
function linear_simulate_evaluate(n, p, use_population;
                                  min_noise = 0.1, max_noise = 0.9, pseudo_pcount = 50,
                                  x_noise = 0.1, y_noise = 0.1,
                                  prob_flip = 0.1, w_effect = 0.2, x_effect = 0.2)

  B, Omega, Sigma, G, dat, vertex_labels = simulate_gaussian(n, p,
     min_noise = min_noise, max_noise = max_noise,
     x_noise = x_noise, y_noise = y_noise,
     prob_flip = prob_flip, w_effect = w_effect, x_effect = x_effect)

  x, y = vertex_labels.x, vertex_labels.y
  best_z = [x; vertex_labels.z3]
  all_z = [x; vertex_labels.z1; vertex_labels.z2; vertex_labels.z3; vertex_labels.z4]
  OK_z = [x; vertex_labels.z2; vertex_labels.z3; vertex_labels.z4]

  if use_population
    S = Sigma
  else
    S = cov(dat)
  end

  ATE_right  = (S[best_z, best_z] \ S[best_z, y])[1]
  ATE_all_z  = (S[all_z, all_z] \ S[all_z, y])[1]
  ATE_OK_z   = (S[OK_z, OK_z] \ S[OK_z, y])[1]
  ATE_margin = S[x, y] / S[x, x]

  return B, Omega, Sigma, G, dat, vertex_labels,
         ATE_right, ATE_all_z, ATE_OK_z, ATE_margin

end

"""
    batch_linear_simulate_evaluate(num_trials, n, p, use_population,
                                   min_noise, max_noise, pseudo_pcount,
                                   x_noise, y_noise,
                                   prob_flip, w_effect, x_effect, label)
Runs `num_trials` trials of a linear model simulation and evaluation. See
the documentation of function `linear_simulate_evaluate` for details about the
arguments.
"""
function batch_linear_simulate_evaluate(num_trials, n, p, use_population,
                                        min_noise, max_noise, pseudo_pcount,
                                        x_noise, y_noise,
                                        prob_flip, w_effect, x_effect, label)

  println()
  println(label)
  println(repeat("=", length(label)))
  println()

  for i = 1:num_trials
    B, Omega, Sigma, G, dat, vertex_labels, ATE_right, ATE_all_z, ATE_OK_z, ATE_margin =
      linear_simulate_evaluate(n, p, use_population;
                               min_noise = min_noise, max_noise = max_noise, pseudo_pcount = pseudo_pcount,
                               x_noise = x_noise, y_noise = y_noise,
                               prob_flip = prob_flip, w_effect = w_effect, x_effect = x_effect)
    @printf("[%2d] Right ATE = %+.2f | All_Z ATE = %+.2f | OK_Z ATE = %+.2f | marginal ATE = %+.2f | IV coeff = %+.2f | ATE coeff = %+.2f \n",
            i, ATE_right, ATE_all_z, ATE_OK_z, ATE_margin,
            B[vertex_labels.x, vertex_labels.w],
            B[vertex_labels.y, vertex_labels.x])
  end

  println()

end

############## DEMO
#
# This runs a demonstration of how we can evaluate the effect of the simulation
# parameters on the baseline estimators In this demo, we have the following
# free parameters:
#
# - num_trials: number of runs
# - n: sample size
# - use_population: use population covariance matrix when assessing baselines
# - p_factor: number of variables of each type to be generated
# - min_noise, max_noise: error term variance will be generated inversely
#                         proportional to the number of parents in the graph,
#                         but always bounded to lie on the interval
#                         [min_noise, max_noise]
# - x_noise, y_noise: except for treatment X and outcome Y. In this case,
#                     the error term variance is given by these variables,
#                     respectively
# - prob_flip: direct causal effects of each variable on their children
#              are initially sampled to have the same sign. To add some
#              variability, with probability prob_flip each coefficient
#              sign will be flipped. When p_factor is large and prob_flip
#              is close to 0.5, confounding and collider effects have high
#              probability of being around zero due to averaging effects.
#              Keeping prob_flip low will help to make problems more difficult.
# - w_effect: coefficient of instrument W on treatment X. Keeping it fixed
#             helps to control for an otherwise diminishing coefficient as
#             p_factor grows. Keep this between -1 and 1, as all variables are
#             standardized. As a matter of fact, this needs to be smaller than
#             1 - x_noise in absolute value
# - x_effect: coefficient of treatment X on outcome Y, with analogous comments
# - sim_label: message to be displayed when running batch of experiments

function demo_linear_simulate_evaluate()
  num_trials, n, use_population = 10, 1000, true
  p_factor = 30
  p = ones(Int, 5) * p_factor
  min_noise, max_noise, pseudo_pcount, x_noise, y_noise = 0.1, 0.9, 50, 0.1, 0.1
  prob_flip, w_effect, x_effect = 0.1, 0.2, 0.2
  sim_label = "DIMENSION = " * string(p_factor) *
              ", FLIP PROBABILITY " * string(prob_flip) *
              ", USE POPULATION = " * string(use_population)
  if !use_population sim_label *=  ", n = " * string(n) end
  batch_linear_simulate_evaluate(num_trials, n, p, use_population,
                     min_noise, max_noise, pseudo_pcount, x_noise, y_noise,
                     prob_flip, w_effect, x_effect, sim_label)
end

################ 2. EVALUATION OF LEARNING ALGORITHMS

"""
    batch_linear_simulate_learn_evaluate(num_trials, n, p, lambda1, lambda2,
         min_noise, max_noise, pseduo_count, x_noise, y_noise,
         prob_flip, w_effect, x_effect, use_population, max_iter, rho)
Runs a series of simulations to assess how our learning algorithm compares to
three main baselines: the "condition on all covariates" baseline, the oracle
that conditions on a minimal set, and the marginal estimator, which makes no
adjustments. The algorithm finds a set of coefficients `theta` so that
`phi == theta' * Z` is used to adjust for confounding, where `Z` is the set of
available covariates.
Most of the parameters are documented as part of the `linear_simulate_evaluate`
function. On top of those, it requires `lambda1` (penalizes weak correlation
between instrument and outcome) and `lambda2` (for now, L2 penalization for
the entries of `theta`). Argument `max_iter` specifies the number of iterations
of the optimization method while `rho` is an internal parameter for
the Adam optimizer used.
This method returns four outputs. `problems` is a vector such that each entry
is a simulated problem. `solutions` contain the corresponding estimated vectors
`theta` of each problem. Each row of `matrix_results` are estiamted ATEs for
each problem, where the first column is the oracle result, the second is the
one learned by our method, the third is the one estimated using all covariates
and the fourth is the marginal estimator. Finally, `wy_corr` contains six
different partial correlations between instrument and outcome for each simulated
problem. Respectively, they are: the partial  correlation given treatment and
`phi` (expected to be close to zero); the partial  correlation given `phi` only
(expected to be reasonably away from zero); the partial  correlation given
treatment only (should not be too weak); the partial correlation given treatment
and all covariates (should not be too weak); the partial correlation given
treatment and the minimal set that blocks confounding (should be close to zero,
exactly zero if `use_population == true`); and finally, the marginal correlation
between instrument and outcome (which should also not be too weak, but this is
not as important).
"""
# function batch_linear_simulate_learn_evaluate(num_trials, n, p, lambda1, lambda2,
#          min_noise, max_noise, pseudo_pcount, x_noise, y_noise,
#          prob_flip, w_effect, x_effect, use_population, max_iter, rho, corr_boost, path_to_file)

#   problems = Vector{LinearProblem}(undef, num_trials)
#   solutions = Vector{Vector{Float64}}(undef, num_trials)
#   matrix_results = Matrix{Float64}(undef, num_trials, 5)
#   wy_corr = Matrix{Float64}(undef, num_trials, 10)

#   diagnosts = RmvDiagnosts([],[],[],[],[],[],[],[],[],[],[],[],[],[])

#   @showprogress for i = 1:num_trials
#     Random.seed!(i);
#     # Generate data
#     B, Omega, Sigma, G, dat, vertex_labels = simulate_gaussian(n, p,
#        min_noise = min_noise, max_noise = max_noise, pseudo_pcount = pseudo_pcount,
#        x_noise = x_noise, y_noise = y_noise,
#        prob_flip = prob_flip, w_effect = w_effect, x_effect = x_effect)

#     w, x, y = vertex_labels.w, vertex_labels.x, vertex_labels.y
#     Z = [vertex_labels.z1; vertex_labels.z2; vertex_labels.z3; vertex_labels.z4]
#     best_Z = vertex_labels.z3
#     use_population ? Sigma_hat = Sigma : Sigma_hat = cov(dat)
#     problems[i] = LinearProblem(B, Omega, Sigma, G, dat, vertex_labels)

#     theta_hat, diagnost_trial = 
#         bd_learn_linear(Sigma_hat, lambda1, lambda2, vertex_labels, i, path_to_file,
#                                 max_iter = max_iter, rho = rho, corr_boost = corr_boost)

#     append!(diagnosts.initial_corr_px , diagnost_trial.initial_corr_px)
#     append!(diagnosts.final_corr_px , diagnost_trial.final_corr_px)

#     solutions[i] = theta_hat
#     norm = L2Penalty()
#     # thresh = 0.01*maximum(norm(thetas.theta))
    
#     sel_Z = findall(x->abs(x)>thresh, theta_hat)
#     # sel_Z = findall(x->abs(x)>1e-3, theta_hat)
#     thresh = 1e-3
#     Sigma_wyx_phi = build_phi_covariance(theta_hat, w, y, x, Z, Sigma_hat)

#     wy_corr[i, 1] = partial_corr([1; 2], [3; 4], Sigma_wyx_phi)[1, 2]
#     wy_corr[i, 2] = partial_corr([1; 2], [4], Sigma_wyx_phi)[1, 2]
#     wy_corr[i, 3] = partial_corr([w; y], [x], Sigma_hat)[1, 2]
#     wy_corr[i, 4] = partial_corr([w; y], [x; Z], Sigma_hat)[1, 2]
#     wy_corr[i, 5] = partial_corr([w; y], [x; best_Z], Sigma_hat)[1, 2]
#     wy_corr[i, 6] = Sigma_hat[x, y] / sqrt(Sigma_hat[x, x] * Sigma_hat[y, y])
#     wy_corr[i, 7] = partial_corr([w; y], [x; vertex_labels.z2; vertex_labels.z3; vertex_labels.z4], Sigma_hat)[1, 2]
#     wy_corr[i, 8] = partial_corr([w; y], [x; vertex_labels.z1; vertex_labels.z2; vertex_labels.z4], Sigma_hat)[1, 2]
#     wy_corr[i, 9] = partial_corr([w; y], [x; vertex_labels.z3; vertex_labels.z4], Sigma_hat)[1, 2]
#     wy_corr[i, 10] = partial_corr([w; y], [x; vertex_labels.z1; vertex_labels.z4], Sigma_hat)[1, 2]


#     ate_hat = (Sigma_wyx_phi[[3; 4], [3; 4]] \ Sigma_wyx_phi[[3; 4], 2])[1]
#     ate_hat_all_Z = (Sigma_hat[[x; Z], [x; Z]] \ Sigma_hat[[x; Z], y])[1]
#     ate_hat_best_Z = (Sigma_hat[[x; best_Z], [x; best_Z]] \ Sigma_hat[[x; best_Z], y])[1]
#     ate_hat_sel_Z = (Sigma_hat[[x; sel_Z], [x; sel_Z]] \ Sigma_hat[[x; sel_Z], y])[1]
#     ate_hat_marg_Z = Sigma_hat[x, y] / Sigma_hat[x, x]

#     matrix_results[i, :] = [ate_hat_best_Z ate_hat ate_hat_all_Z ate_hat_sel_Z ate_hat_marg_Z]

#   end
#   return problems, solutions, matrix_results, wy_corr, diagnosts

# end

"""
    print_linear_simulate_learn_evaluate(matrix_results, wy_corr)
Print the output of a call to `batch_linear_simulate_learn_evaluate`.
"""
# function print_linear_simulate_learn_evaluate(matrix_results, wy_corr, solutions, lambda2, path_to_file)
#   num_trials = size(matrix_results)[1]

#   err_learned = abs.(matrix_results[:, 2] - matrix_results[:, 1])
#   err_zsel_learned = abs.(matrix_results[:, 4] - matrix_results[:, 1])
#   err_all_Z = abs.(matrix_results[:, 3] - matrix_results[:, 1])
#   err_marg_Z = abs.(matrix_results[:, 5] - matrix_results[:, 1])

#   mean_err_learned = mean(err_learned)
#   mean_err_zsel_learned = mean(err_zsel_learned)
#   mean_err_all_Z   = mean(err_all_Z)
#   mean_err_marg_Z  = mean(err_marg_Z)

#   sem_err_learned = sem(err_learned)
#   sem_err_zsel_learned = sem(err_zsel_learned)
#   sem_err_all_Z   = sem(err_all_Z)
#   sem_err_marg_Z  = sem(err_marg_Z)

#   med_err_learned = median(err_learned)
#   med_err_zsel_learned = median(err_zsel_learned)
#   med_err_all_Z   = median(err_all_Z)
#   med_err_marg_Z  = median(err_marg_Z)

#   mad_err_learned = mad(err_learned, normalize=true)
#   mad_err_zsel_learned = mad(err_zsel_learned, normalize=true)
#   mad_err_all_Z   = mad(err_all_Z, normalize=true)
#   mad_err_marg_Z  = mad(err_marg_Z, normalize=true)

#   iqr_err_learned = iqr(err_learned)
#   iqr_err_zsel_learned = iqr(err_zsel_learned)
#   iqr_err_all_Z  = iqr(err_all_Z)
#   iqr_err_marg_Z = iqr(err_marg_Z)

#   @printf("LEARNED *MEAN* ATE ERROR = %.5f sem %.3f\n", mean_err_learned, sem_err_learned)
#   @printf("ZSEL_LEARNED *MEAN* ATE ERROR = %.5f sem %.3f\n", mean_err_zsel_learned, sem_err_zsel_learned)
#   @printf("ALL_Z *MEAN* ATE ERROR = %.5f sem %.3f\n", mean_err_all_Z, sem_err_all_Z)
#   @printf("MARG *MEAN* ATE ERROR = %.5f sem %.3f\n", mean_err_marg_Z, sem_err_marg_Z)

#   println("----------------------")
#   println("----------------------")

#   @printf("LEARNED *MEDIAN* ATE ERROR = %.5f mad = %.3f 75p-25p = %.3f\n", med_err_learned,
#     mad_err_learned, iqr_err_learned)
#   @printf("ZSEL_LEARNED *MEDIAN* ATE ERROR = %.5f mad = %.3f 75p-25p = %.3f\n", med_err_zsel_learned,
#     mad_err_zsel_learned, iqr_err_zsel_learned)
#   @printf("ALL_Z *MEDIAN* ATE ERROR = %.5f mad = %.3f 75p-25p = %.3ff\n", med_err_all_Z,
#     mad_err_all_Z, iqr_err_all_Z)
#   @printf("MARG *MEDIAN* ATE ERROR = %.5f mad = %.3f 75p-25p = %.3f\n", med_err_marg_Z,
#     mad_err_marg_Z, iqr_err_marg_Z)

#   open(path_to_file*"outputfiles/results.txt", "w") do f
#     write(f, "LAMBDA is =$lambda2 \n")

#     write(f, "LEARNED *MEAN* ATE ERROR = ", repr(mean_err_learned, context=:compact => true),
#       " sem ", repr(sem_err_learned, context=:compact => true), "\n")
#     write(f, "ZSEL_LEARNED *MEAN* ATE ERROR = ", repr(mean_err_zsel_learned, context=:compact => true),
#       " sem ", repr(sem_err_zsel_learned, context=:compact => true), "\n")
#     write(f, "ALL_Z *MEAN* ATE ERROR = ", repr(mean_err_all_Z, context=:compact => true),
#       " sem ", repr(sem_err_all_Z, context=:compact => true), "\n")
#     write(f, "MARG *MEAN* ATE ERROR = ", repr(mean_err_marg_Z, context=:compact => true),
#       " sem ", repr(sem_err_marg_Z, context=:compact => true), "\n")

#     write(f, "\n----------------------\n")
#     write(f, "\n----------------------\n")

#     write(f, "LEARNED *MEDIAN* ATE ERROR = ", repr(med_err_learned, context=:compact => true),
#       " mad = ", repr(mad_err_learned, context=:compact => true),
#       " 75p-25p = ", repr(iqr_err_learned, context=:compact => true), "\n")
#     write(f, "ZSEL_LEARNED *MEDIAN* ATE ERROR = ", repr(med_err_zsel_learned, context=:compact => true),
#       " mad = ", repr(mad_err_zsel_learned, context=:compact => true),
#       " 75p-25p = ", repr(iqr_err_zsel_learned, context=:compact => true), "\n")
#     write(f, "ALL_Z *MEDIAN* ATE ERROR = ", repr(med_err_all_Z, context=:compact => true),
#       " mad = ", repr(mad_err_all_Z, context=:compact => true),
#       " 75p-25p = ", repr(iqr_err_all_Z, context=:compact => true), "\n")
#     write(f, "MARG *MEDIAN* ATE ERROR = ", repr(med_err_marg_Z, context=:compact => true),
#       " mad = ", repr(mad_err_marg_Z, context=:compact => true),
#       " 75p-25p = ", repr(iqr_err_marg_Z, context=:compact => true), "\n")

#     write(f, "\n----------------------\n")
#     write(f, "\n----------------------\n")

#     write(f, "LEARNED ATE ERROR = ", repr(err_learned, context=:compact => true), "\n")
#     write(f, "ZSEL_LEARNED ATE ERROR = ", repr(err_zsel_learned, context=:compact => true), "\n")
#     write(f, "ALL_Z ATE ERROR = ", repr(err_all_Z, context=:compact => true), "\n")
#     write(f, "MARG ATE ERROR = ", repr(err_marg_Z, context=:compact => true), "\n")

#     write(f, "\n----------------------\n")
#     write(f, "\n----------------------\n")
#   end

# end

function process_ATEs(hypo_fail_all_lambdas, path_to_file)
  corr_px_valid = []
  num_trials = length(hypo_fail_all_lambdas)

  err_learned_train = zeros(num_trials)
  err_zsel_learned_train = zeros(num_trials)
  err_all_Z_train = zeros(num_trials)
  err_marg_Z_train = zeros(num_trials)
  err_learned_valid = zeros(num_trials)
  err_zsel_learned_valid = zeros(num_trials)
  err_all_Z_valid = zeros(num_trials)
  err_marg_Z_valid = zeros(num_trials)

  err_learned_B_train = zeros(num_trials)
  err_zsel_learned_B_train = zeros(num_trials)
  err_all_Z_B_train = zeros(num_trials)
  err_marg_Z_B_train = zeros(num_trials)
  err_learned_B_valid = zeros(num_trials)
  err_zsel_learned_B_valid = zeros(num_trials)
  err_all_Z_B_valid = zeros(num_trials)
  err_marg_Z_B_valid = zeros(num_trials)

  for i=1:num_trials

    err_learned_train[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_train"][3] - 
      hypo_fail_all_lambdas[i]["ATE_results_train"][2])

    err_zsel_learned_train[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_train"][5] - 
      hypo_fail_all_lambdas[i]["ATE_results_train"][2])

    err_all_Z_train[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_train"][4] - 
      hypo_fail_all_lambdas[i]["ATE_results_train"][2])

    err_marg_Z_train[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_train"][6] - 
      hypo_fail_all_lambdas[i]["ATE_results_train"][2])

    err_learned_valid[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_valid"][3] - 
      hypo_fail_all_lambdas[i]["ATE_results_valid"][2])
    err_zsel_learned_valid[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_valid"][5] - 
      hypo_fail_all_lambdas[i]["ATE_results_valid"][2])
    err_all_Z_valid[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_valid"][4] - 
      hypo_fail_all_lambdas[i]["ATE_results_valid"][2])
    err_marg_Z_valid[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_valid"][6] - 
      hypo_fail_all_lambdas[i]["ATE_results_valid"][2])

    err_learned_B_train[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_train"][3] - 
      hypo_fail_all_lambdas[i]["ATE_results_train"][1])

    err_zsel_learned_B_train[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_train"][5] - 
      hypo_fail_all_lambdas[i]["ATE_results_train"][1])

    err_all_Z_B_train[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_train"][4] - 
      hypo_fail_all_lambdas[i]["ATE_results_train"][1])

    err_marg_Z_B_train[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_train"][6] - 
      hypo_fail_all_lambdas[i]["ATE_results_train"][1])

    err_learned_B_valid[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_valid"][3] - 
      hypo_fail_all_lambdas[i]["ATE_results_valid"][1])
    err_zsel_learned_B_valid[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_valid"][5] - 
      hypo_fail_all_lambdas[i]["ATE_results_valid"][1])
    err_all_Z_B_valid[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_valid"][4] - 
      hypo_fail_all_lambdas[i]["ATE_results_valid"][1])
    err_marg_Z_B_valid[i] = abs.(hypo_fail_all_lambdas[i]["ATE_results_valid"][6] - 
      hypo_fail_all_lambdas[i]["ATE_results_valid"][1])

    append!(corr_px_valid, hypo_fail_all_lambdas[i]["corr_px_valid"])
  end

  # training scatter plots
  abline = Geom.abline(color="red", style=:dash)

  max_value_plot_train = max(maximum(err_learned_train), maximum(err_zsel_learned_train), 
    maximum(err_all_Z_train), maximum(err_marg_Z_train)) + 0.01
  max_value_plot_valid = max(maximum(err_learned_valid), maximum(err_zsel_learned_valid), 
    maximum(err_all_Z_valid), maximum(err_marg_Z_valid)) + 0.01

  max_value_plot_B_train = max(maximum(err_learned_B_train), maximum(err_zsel_learned_B_train), 
    maximum(err_all_Z_B_train), maximum(err_marg_Z_B_train)) + 0.01
  max_value_plot_B_valid = max(maximum(err_learned_B_valid), maximum(err_zsel_learned_B_valid), 
    maximum(err_all_Z_B_valid), maximum(err_marg_Z_B_valid)) + 0.01

  p1_train = plot(x = err_learned_train, y = err_marg_Z_train, Geom.point, Theme(default_color=colorant"purple"),
    layer(x = err_zsel_learned_train, y = err_marg_Z_train, Geom.point, Theme(default_color=colorant"orange")), 
    abline, Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_train), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_train),
    Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-marginal ATE|"),
    Guide.manual_color_key("", ["learned phi", "learned phi + Zsel"],
                            ["purple", "orange"]))
 
  p2_train = plot(x = err_learned_train, y = err_all_Z_train, Geom.point, Theme(default_color=colorant"purple"),
    layer(x = err_zsel_learned_train, y = err_all_Z_train, Geom.point, Theme(default_color=colorant"orange")), 
    abline, Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-allZ ATE|"),
  Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_train), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_train),
  Guide.manual_color_key("", ["learned phi", "learned phi + Zsel"],
                            ["purple", "orange"]))

  p1_B_train = plot(x = err_learned_B_train, y = err_marg_Z_B_train, Geom.point, Theme(default_color=colorant"purple"),
    layer(x = err_zsel_learned_B_train, y = err_marg_Z_B_train, Geom.point, Theme(default_color=colorant"orange")), 
    abline, Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_B_train), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_B_train),
    Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-marginal ATE|"),
    Guide.manual_color_key("", ["learned phi", "learned phi + Zsel"],
                            ["purple", "orange"]))
 
  p2_B_train = plot(x = err_learned_B_train, y = err_all_Z_B_train, Geom.point, Theme(default_color=colorant"purple"),
    layer(x = err_zsel_learned_B_train, y = err_all_Z_B_train, Geom.point, Theme(default_color=colorant"orange")), 
    abline, Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-allZ ATE|"),
  Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_B_train), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_B_train),
  Guide.manual_color_key("", ["learned phi", "learned phi + Zsel"],
                            ["purple", "orange"]))

  p_train = hstack(p1_train, p2_train)
  p_B_train = hstack(p1_B_train, p2_B_train)
  plot(p_train)
  # p_train
  draw(SVG(path_to_file*"outputfiles/scatter_train.svg", 8inch, 4inch), p_train)
  draw(SVG(path_to_file*"outputfiles/scatter_B_train.svg", 8inch, 4inch), p_B_train)

  # validation scatter plots
  p1_valid = plot(x = err_learned_valid, y = err_marg_Z_valid, Geom.point, Theme(default_color=colorant"purple"),
  layer(x = err_zsel_learned_valid, y = err_marg_Z_valid, Geom.point, Theme(default_color=colorant"orange")), abline,
   Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-marginal ATE|"), 
    Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_valid), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_valid),
    Guide.manual_color_key("",["learned phi", "learned phi + Zsel"],
                            ["purple", "orange"]))

  p2_valid = plot(x = err_learned_valid, y = err_all_Z_valid, Geom.point, Theme(default_color=colorant"purple"),
    layer(x = err_zsel_learned_valid, y = err_all_Z_valid, Geom.point, Theme(default_color=colorant"orange")),
    abline, Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-allZ ATE|"), 
    Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_valid), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_valid),
    Guide.manual_color_key("", ["learned phi", "learned phi + Zsel"],
                            ["purple", "orange"]))

  p1_B_valid = plot(x = err_learned_B_valid, y = err_marg_Z_B_valid, Geom.point, Theme(default_color=colorant"purple"),
  layer(x = err_zsel_learned_B_valid, y = err_marg_Z_B_valid, Geom.point, Theme(default_color=colorant"orange")), abline,
   Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-marginal ATE|"), 
    Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_B_valid), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_B_valid),
    Guide.manual_color_key("",["learned phi", "learned phi + Zsel"],
                            ["purple", "orange"]))

  p2_B_valid = plot(x = err_learned_B_valid, y = err_all_Z_B_valid, Geom.point, Theme(default_color=colorant"purple"),
    layer(x = err_zsel_learned_B_valid, y = err_all_Z_B_valid, Geom.point, Theme(default_color=colorant"orange")),
    abline, Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-allZ ATE|"), 
    Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_B_valid), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_B_valid),
    Guide.manual_color_key("", ["learned phi", "learned phi + Zsel"],
                            ["purple", "orange"]))

  p_valid = hstack(p1_valid, p2_valid)
  p_B_valid = hstack(p1_B_valid, p2_B_valid)
  plot(p_valid)
  # p_valid
  draw(SVG(path_to_file*"outputfiles/scatter_valid.svg", 8inch, 4inch), p_valid)
  draw(SVG(path_to_file*"outputfiles/scatter_B_valid.svg", 8inch, 4inch), p_B_valid)

  # f_entener_train = pybuiltin("open")("train_ATE_errs.p","rb")
  # p_entener_train = pickle.Unpickler(f_entener_train)
  # err_entner_train = p_entener_train.load()
  # f_entener_train.close()

  # f_entener_valid = pybuiltin("open")("valid_ATE_errs.p","rb")
  # p_entener_valid = pickle.Unpickler(f_entener_valid)
  # err_entner_valid = p_entener_valid.load()
  # f_entener_valid.close()

  # p1_entner = plot(x = err_learned_B_train, y = err_entner_train, Geom.point, Theme(default_color=colorant"purple"),
  # layer(x = err_zsel_learned_B_train, y = err_entner_train, Geom.point, Theme(default_color=colorant"orange")), abline,
  #  Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-Entner ATE|"), 
  #   Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_B_valid), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_B_valid),
  #   Guide.manual_color_key("",["learned phi", "learned phi + Zsel"],
  #                           ["purple", "orange"]))

  # p2_entner = plot(x = err_learned_B_valid, y = err_entner_valid, Geom.point, Theme(default_color=colorant"purple"),
  #   layer(x = err_zsel_learned_B_valid, y = err_entner_valid, Geom.point, Theme(default_color=colorant"orange")),
  #   abline, Guide.xlabel("|real ATE-learned ATE|"), Guide.ylabel("|real ATE-Entner ATE|"), 
  #   Scale.x_continuous(minvalue=0, maxvalue=max_value_plot_B_valid), Scale.y_continuous(minvalue=0, maxvalue=max_value_plot_B_valid),
  #   Guide.manual_color_key("", ["learned phi", "learned phi + Zsel"],
  #                           ["purple", "orange"]))

  # p_entner = hstack(p1_entner, p2_entner)
  # draw(SVG(path_to_file*"outputfiles/scatter_entner.svg", 8inch, 4inch), p_valid)

  # ATEs df
  ATEs = DataFrame(mean_err_learned = [mean(err_learned_train), mean(err_learned_valid)],
    mean_err_learned_w_zsel = [mean(err_zsel_learned_train), mean(err_zsel_learned_valid)],
    mean_err_marg = [mean(err_marg_Z_train), mean(err_marg_Z_valid)],
    mean_err_allZ = [mean(err_all_Z_train), mean(err_all_Z_valid)])

  ATE_Bs = DataFrame(mean_err_learned = [mean(err_learned_B_train), mean(err_learned_B_valid)],
    mean_err_learned_w_zsel = [mean(err_zsel_learned_B_train), mean(err_zsel_learned_B_valid)],
    mean_err_marg = [mean(err_marg_Z_B_train), mean(err_marg_Z_B_valid)],
    mean_err_allZ = [mean(err_all_Z_B_train), mean(err_all_Z_B_valid)])  

  open(path_to_file*"outputfiles/ATE_table.txt", "a") do file
    write(file, repr("text/latex", ATEs))
    write(file, "\n")
    write(file, "\n")
    write(file, repr("text/latex", ATE_Bs))
  end

  ATEs_full = Dict("err_learned_train"=>err_learned_train,
   "err_learned_valid"=>err_learned_valid, 
   "err_zsel_learned_train"=>err_zsel_learned_train,
   "err_zsel_learned_valid"=>err_zsel_learned_valid, 
   "err_marg_Z_train"=>err_marg_Z_train,
   "err_marg_Z_valid"=>err_marg_Z_valid, 
   "err_all_Z_train"=>err_all_Z_train, 
   "err_all_Z_valid"=>err_all_Z_valid)

  ATEs_B_full = Dict("err_learned_train"=>err_learned_B_train,
   "err_learned_valid"=>err_learned_B_valid, 
   "err_zsel_learned_train"=>err_zsel_learned_B_train,
   "err_zsel_learned_valid"=>err_zsel_learned_B_valid, 
   "err_marg_Z_train"=>err_marg_Z_B_train,
   "err_marg_Z_valid"=>err_marg_Z_B_valid, 
   "err_all_Z_train"=>err_all_Z_B_train, 
   "err_all_Z_valid"=>err_all_Z_B_valid)

  open(path_to_file*"ATE_table.txt", "a") do file
    write(file, repr("text/latex", ATEs))
  end

  open(path_to_file*"ATEs_full.txt", "w") do file
    write(file, repr(ATEs_full))
  end

  open(path_to_file*"ATEs_B_full.txt", "w") do file
    write(file, repr(ATEs_B_full))
  end
  println()
  println("---------------------------------")
  println("first row train, second row valid")
  println("---------------------------------")
  println()
  println(ATEs)
  # println("mean of corr_px_valid")
  # println(mean(corr_px_valid))
  # println("median of corr_px_valid")
  # println(median(corr_px_valid))
  println()
  println("---------------------------------")
  println("comparison to weight on X->Y")
  println("first row train, second row valid")
  println("---------------------------------")
  println()
  println(ATE_Bs)

  pick_trial_num = rand(collect(1:num_trials),30)

  open(path_to_file*"outputfiles/Z_sel.txt", "w") do file
    for index in pick_trial_num
      # thresh = 0.01*maximum(norm(hypo_fail_all_lambdas[index]["theta_hat"]))
      thresh = 1e-3
      write(file, "--------\n")
      num_selected = length(findall(x->abs(x)>thresh, hypo_fail_all_lambdas[index]["theta_hat"]))
      write(file, "# zs selected: $num_selected\n")
      println("# zs selected: $num_selected\n")
      write(file, "z selected: \n")
      write(file, repr(findall(x->abs(x)>thresh, hypo_fail_all_lambdas[index]["theta_hat"])))
      println("\n")
      println(repr(findall(x->abs(x)>thresh, hypo_fail_all_lambdas[index]["theta_hat"])))
      println("\n")
      write(file, "\n")
      write(file, "theta: \n")
      write(file, repr(hypo_fail_all_lambdas[index]["theta_hat"]))
      write(file, "\n")
      write(file, "--------\n")
    end
  end
  
end

function choose_lambdas(lambda_twos, lambda1, i, n, p, num_Z, min_noise, max_noise, pseudo_pcount, x_noise, y_noise,
         prob_flip, w_effect, x_effect, use_population, max_iter, lrs, corr_boost, path_to_file)
  initial_lambda1 = lambda1
  ATE_results_train = Matrix{Float64}(undef, 1, 6)
  ATE_results_valid = Matrix{Float64}(undef, 1, 6)
  corr_pxs = Dict() 
  hypo_fail_all_lambdas = Dict()
  Random.seed!(i);
  # Generate data
  # training set
  B_train, Omega_train, Sigma_train, G_train, dat_train, vertex_labels = simulate_gaussian(n, p,
     min_noise = min_noise, max_noise = max_noise, pseudo_pcount = pseudo_pcount,
     x_noise = x_noise, y_noise = y_noise,
     prob_flip = prob_flip, w_effect = w_effect, x_effect = x_effect)
  # validation set
  B_valid, Omega_valid, Sigma_valid, G_valid, dat_valid, _ = simulate_gaussian(n, p,
  min_noise = min_noise, max_noise = max_noise, pseudo_pcount = pseudo_pcount,
  x_noise = x_noise, y_noise = y_noise,
  prob_flip = prob_flip, w_effect = w_effect, x_effect = x_effect)

  f = pybuiltin("open")(path_to_file*"outputfiles/train_data_$i.pickle","wb")
  p = pickle.Pickler(f)
  p.dump(dat_train)
  f.close()

  f_real_ATE = pybuiltin("open")(path_to_file*"outputfiles/train_real_ATE_$i.pickle","wb")
  p_real_ATE = pickle.Pickler(f_real_ATE)
  p_real_ATE.dump(B_train[vertex_labels.x, vertex_labels.y])
  f_real_ATE.close()

  f2 = pybuiltin("open")(path_to_file*"outputfiles/valid_data_$i.pickle","wb")
  p2 = pickle.Pickler(f2)
  p2.dump(dat_valid)
  f2.close()

  f_real_ATE_valid = pybuiltin("open")(path_to_file*"outputfiles/valid_real_ATE_$i.pickle","wb")
  p_real_ATE_valid = pickle.Pickler(f_real_ATE_valid)
  p_real_ATE_valid.dump(B_valid[vertex_labels.x, vertex_labels.y])
  f_real_ATE_valid.close()

  # graph definitions
  w, x, y = vertex_labels.w, vertex_labels.x, vertex_labels.y
  Z = [vertex_labels.z1; vertex_labels.z2; vertex_labels.z3; vertex_labels.z4]
  best_Z = vertex_labels.z3

  # Sigma train construction
  use_population ? Sigma_hat = Sigma_train : Sigma_hat = cov(dat_train)
  for lambda2 in lambda_twos
    # println("lambda2: ", lambda2)
    for lr in lrs
      hypo_fail = Dict()
      # println("lr: ", lr)
      reject_null_hypothesis = false
      lambda1 = initial_lambda1
      bonferonni_correction = 1.
      while (!reject_null_hypothesis)
        # println("lambda1: ", lambda1)
        # learn theta on training set
        theta_hat, corr_px_theta_hat, corr_p_theta_hat = 
            bd_learn_linear(Sigma_hat, lambda1, lambda2, vertex_labels, i, path_to_file,
                                    max_iter = max_iter, lr = lr, corr_boost = corr_boost)

        # println("corr_p_theta_hat: ", corr_p_theta_hat)
        # definition of sel_Z
        # thresh = 0.01*maximum(norm(theta_hat))
        thresh = 1e-3
        sel_Z = findall(x->abs(x)>thresh, theta_hat)
        # test for the null hypothesis
        reject_null_hypothesis = 
          ind_null_hypo(n, num_Z, corr_p_theta_hat; significance_level=(0.01/bonferonni_correction))
        # if null rejected, i.e. reject_null_hypothesis=true
        if reject_null_hypothesis
          # compute ATEs training set
          Sigma_wyx_phi = build_phi_covariance(theta_hat, w, y, x, Z, Sigma_hat)

          atr_real_train = B_train[vertex_labels.y, vertex_labels.x]
          ate_hat_train = (Sigma_wyx_phi[[3; 4], [3; 4]] \ Sigma_wyx_phi[[3; 4], 2])[1]
          ate_hat_all_Z_train = (Sigma_hat[[x; Z], [x; Z]] \ Sigma_hat[[x; Z], y])[1]
          ate_hat_best_Z_train = (Sigma_hat[[x; best_Z], [x; best_Z]] \ Sigma_hat[[x; best_Z], y])[1]
          ate_hat_sel_Z_train = (Sigma_hat[[x; sel_Z], [x; sel_Z]] \ Sigma_hat[[x; sel_Z], y])[1]
          ate_hat_marg_Z_train = Sigma_hat[x, y] / Sigma_hat[x, x]

          ATE_results_train = [atr_real_train ate_hat_best_Z_train ate_hat_train ate_hat_all_Z_train ate_hat_sel_Z_train ate_hat_marg_Z_train]
          # ATE_results_train = [ate_hat_best_Z_train ate_hat_train ate_hat_all_Z_train ate_hat_sel_Z_train ate_hat_marg_Z_train]

          # compute \rho(W,Y|beta*Z, X) validation
          use_population ? Sigma_hat_valid = Sigma_valid : Sigma_hat_valid = cov(dat_valid)
          Sigma_wyx_phi_valid = build_phi_covariance(theta_hat, w, 
            x, y, Z, Sigma_hat_valid)
          try      
            corr_px_valid = abs(partial_corr([1; 2], [3; 4], Sigma_wyx_phi_valid)[1, 2])
            # compute ATEs validation set
            atr_real_valid = B_valid[vertex_labels.y, vertex_labels.x]
            ate_hat_valid = (Sigma_wyx_phi_valid[[3; 4], [3; 4]] \ Sigma_wyx_phi_valid[[3; 4], 2])[1]
            ate_hat_all_Z_valid = (Sigma_hat_valid[[x; Z], [x; Z]] \ Sigma_hat_valid[[x; Z], y])[1]
            ate_hat_best_Z_valid = (Sigma_hat_valid[[x; best_Z], [x; best_Z]] \ Sigma_hat_valid[[x; best_Z], y])[1]
            ate_hat_sel_Z_valid = (Sigma_hat_valid[[x; sel_Z], [x; sel_Z]] \ Sigma_hat_valid[[x; sel_Z], y])[1]
            ate_hat_marg_Z_valid = Sigma_hat_valid[x, y] / Sigma_hat_valid[x, x]

            ATE_results_valid = [atr_real_valid ate_hat_best_Z_valid ate_hat_valid ate_hat_all_Z_valid ate_hat_sel_Z_valid ate_hat_marg_Z_valid]
            # ATE_results_valid = [ate_hat_best_Z_valid ate_hat_valid ate_hat_all_Z_valid ate_hat_sel_Z_valid ate_hat_marg_Z_valid]
            # save corrs
            hypo_fail["corr_px_train"] = corr_px_theta_hat
            hypo_fail["corr_p_train"] = corr_p_theta_hat
            hypo_fail["corr_px_valid"] = corr_px_valid
            hypo_fail["lr"] = lr
            # parameters
            hypo_fail["theta_hat"] = theta_hat
            hypo_fail["lambda1"] = lambda1
            hypo_fail["lambda2"] = lambda2
            # ATEs train
            hypo_fail["ATE_results_train"] = ATE_results_train
            # ATEs valid
            hypo_fail["ATE_results_valid"] = ATE_results_valid
            hypo_fail_all_lambdas[hypo_fail["corr_px_valid"]] = hypo_fail
            break
          catch
            lambda1 = lambda1 * 2
            bonferonni_correction += 1.
          end
        else
          lambda1 = lambda1 * 2
          bonferonni_correction += 1.
        end
      end
    end
  end
  best_setup = hypo_fail_all_lambdas[minimum(keys(hypo_fail_all_lambdas))]
  if best_setup["corr_px_valid"] > 0.09
    println("bad corr_px_valid: ", best_setup["corr_px_valid"])
  end
  return hypo_fail_all_lambdas[minimum(keys(hypo_fail_all_lambdas))]
end
############## DEMO
#
# This runs a demonstration of the learning algorithm using `num_trials`
# simulations. Refer to `batch_linear_simulate_learn_evaluate` for an
# explanation of parametrs and outputs.

function demo_linear_simulate_learn_evaluate(num_trials, path_to_file; lambda_twos=[5e-2], lambda1=5e-6, 
  lrs=0.00001, x_noise=0.01)
  matrix_results = Matrix{Float64}(undef, num_trials, 6)
  wy_corr = Matrix{Float64}(undef, num_trials, 10)
  solutions = Vector{Vector{Float64}}(undef, num_trials)
  matrix_thetas = Matrix{Float64}(undef, num_trials, 5)
  # diagnost = RmvDiagnosts([],[],[],[],[],[],[],[],[],[],[],[],[],[])
  num_Z = 4*30
  n, p = 10000, ones(Int, 5) * 30
  min_noise, max_noise, pseudo_pcount, y_noise = 0.1, 0.5, 50, 0.1
  prob_flip, w_effect, x_effect = 0.1, 0.1, 0.1
  use_population = false
  corr_boost = 1
  max_iter, rho = 1000, lrs
  reject_null_hypothesis = true

  results_all_trials = Dict()

  for i=1:num_trials

    println()
    println("Solving simulation $i / $num_trials...")
  
    best_lambdas_for_trial = 
    choose_lambdas(lambda_twos, lambda1, i, n, p, num_Z, min_noise, max_noise, pseudo_pcount, x_noise, y_noise,
           prob_flip, w_effect, x_effect, use_population, max_iter, lrs, corr_boost, path_to_file)   

    println("chosen lambda1_: ", best_lambdas_for_trial["lambda1"])
    println("chosen lambda2_: ", best_lambdas_for_trial["lambda2"])
    println("chosen lr_: ", best_lambdas_for_trial["lr"])
    println("partial correlation on validation set: ", best_lambdas_for_trial["corr_px_valid"])

    results_all_trials[i] = best_lambdas_for_trial
  end

  open(path_to_file*"results_all_trials.txt", "w") do file
    write(file, repr(results_all_trials))
  end

  process_ATEs(results_all_trials, path_to_file)
end