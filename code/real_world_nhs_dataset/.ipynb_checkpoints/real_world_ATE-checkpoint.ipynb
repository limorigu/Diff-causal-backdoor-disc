{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct VertexLabels\n",
    "  u1::Vector{Int}  # Latent variables, parents of colliders Z1 and outcome Y\n",
    "  u2::Vector{Int}  # Latent variables, parents of colliders Z1 and treatment X\n",
    "  w::Vector{Int}       # Instrument\n",
    "  x::Vector{Int}       # Treatment\n",
    "  y::Vector{Int}       # Outcome\n",
    "  z1::Vector{Int}  # Colliders between X and Y\n",
    "  z3::Vector{Int}  # Confounders between X and Y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = collect(1:1)\n",
    "x = collect(2:2)\n",
    "y = collect(3:3)\n",
    "u1 = collect(4:8)\n",
    "u2 = collect(9:13)\n",
    "z1 = collect(14:18)\n",
    "z3 = collect(19:25)\n",
    "vertex_labels = VertexLabels(u1, u2, w, x, y, z1, z3)\n",
    "n = 60000\n",
    "num_vertices = 25\n",
    "dat = zeros(n, num_vertices);\n",
    "#read in dataset\n",
    "i = 1\n",
    "for row in CSV.Rows(\"nhs_data_60000.csv\", datarow=2)\n",
    "    dat[i,:] = [parse(Float64, x) for x in row[2:end]]\n",
    "    i+=1\n",
    "end\n",
    "\n",
    "# dat = dat[1:20000,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: extra token \"estimate_effects\" after end of expression",
     "output_type": "error",
     "traceback": [
      "syntax: extra token \"estimate_effects\" after end of expression",
      ""
     ]
    }
   ],
   "source": [
    "# code inspired by makeDecisionAndEstimateEffect_3classes.m AND \n",
    "#\t\t\t\t   calculateEstimatedEffect.m\n",
    "# INPUT\n",
    "# data\n",
    "# D (n,d+3)... data matrix\n",
    "#   (n,d)  ... Z covariates\n",
    "#   (n,)   ... W auxiliary variable\n",
    "#   (n,)   ... X treatment\n",
    "#   (n,)   ... Y outcome\n",
    "# datatype ... string: 'continuous' if data are Gaussain\n",
    "#                      'discrete' if data are discrete\n",
    "# p_vals_wy_zx ... p-values from tests\n",
    "# p_vals_wy_z  ... p-values from tests\n",
    "# Zsels  ... selected Zs\n",
    "#\n",
    "# OUTPUT\n",
    "# est ... estiamte of the causal effect of x on y, or NaN\n",
    "# Dec ... decision: 1 for D1, 2 for D2, 3 for D3, 4 if Decision from Naive\n",
    "#         Bayes classifier was D1, but estimates were not similar enough, so\n",
    "#         we do not give an estimate of the causal effect of x on y, i.e. est\n",
    "#         is the following depending on Dec:\n",
    "#         if Decision is D1 (i.e. Dec=1) est is the estimate of the non-zero\n",
    "#         effect of x on y. For D2 (i.e. Dec=2), est = 0; For D3 (i.e.\n",
    "#         Dec=3), or Dec=4, est = NaN;\n",
    "# post_prob = class posterior probabilities of D1, D2, and D3 (in this order)\n",
    "def estimate_effects(D, datatype, p_vals_wy_zx, p_vals_wy_z, Zsels):\n",
    "\n",
    "\t(n,d3) = D.shape\n",
    "\tixY    = d3-1\n",
    "\tixX    = d3-2\n",
    "\tixW    = d3-3\n",
    "\tixZ    = np.arange(d3-3)\n",
    "\td      = d3-3\n",
    "\tt      = p_vals_wy_zx.shape[0]\n",
    "\tp_reject = 0.001\n",
    "\tp_accept = 0.1\n",
    "\t# if datatype == 'continuous':\n",
    "\t# \t# assuming n >= 5000\n",
    "\t# \tp_reject = 0.001\n",
    "\t# \tp_accept = 0.1\n",
    "\t# elif datatype == 'discrete':\n",
    "\t# \titest = 'logOdds'\n",
    "\t# \tcov = D\n",
    "\t# else:\n",
    "\t# \terror('no such datatype')\n",
    "\n",
    "\t# NOTE: we do not use this code as it is only to check if R1 or R2/R3 \n",
    "\t#       applies (we assume R3 applies) \n",
    "\t# getCountsFromPvalues.m\n",
    "\t# ----------------------\n",
    "\t# cntR3 = sum( temp{3}(:,2) > p_accept & temp{3}(:,3) < p_reject)\n",
    "\t# cntR3 = np.sum(p_vals_wy_zx > p_accept & p_vals_wy_z < p_reject)\n",
    "\t# cntR3_norm = cntR3/t\n",
    "\n",
    "\t# calculateEstimatedEffect.m\n",
    "\t# --------------------------\n",
    "\t#bool = temp(:,2) > p_accept & temp(:,3) < p_reject\n",
    "\tbool = np.logical_and((p_vals_wy_zx > p_accept),(p_vals_wy_z < p_reject))\n",
    "\tZaccept = np.array(Zsels)[bool]\n",
    "\ttimes = Zaccept.shape[0]\n",
    "\t\n",
    "\tif datatype == 'continuous':\n",
    "\t\tb = np.ones((n,1))\n",
    "\t\tDx = D[:,ixX].reshape((n,1))\n",
    "\t\tDy = D[:,ixY].reshape((n,1))\n",
    "\t\tif times == 0:\n",
    "\t\t\tX = np.concatenate((b, Dx), axis=1)\n",
    "\t\t\tC = np.dot(X.transpose(), X)\n",
    "\t\t\tXy= np.dot(X.transpose(), Dy)\n",
    "\t\t\ttheta = np.linalg.solve(C, Xy)\n",
    "\t\t\tate = theta[1]\n",
    "\t\telse:\n",
    "\t\t\tate = np.zeros((times,))\n",
    "\t\t\tfor i in range(times):\n",
    "\t\t\t\tZ = Zaccept[i]\n",
    "\t\t\t\tif Z.shape[0] == 0:\n",
    "\t\t\t\t\tX = np.concatenate((b, Dx), axis=1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tX = np.concatenate((b, Dx, D[:,Z]), axis=1)\n",
    "\t\t\t\t\t# (X'X)^-1(X'y)\n",
    "\t\t\t\tC = np.dot(X.transpose(), X)\n",
    "\t\t\t\tXy= np.dot(X.transpose(), Dy)\n",
    "\t\t\t\ttheta = np.linalg.solve(C, Xy)\n",
    "\t\t\t\t# NOTE: we do not check if estimates are similar\n",
    "\t\t\t\t#\t\tand output NaN if so, as in the original\n",
    "\t\t\t\t#       code via:\n",
    "    \t\t\t# val = areEstiamtesSimilar_Clusters(ests, CIs);\n",
    "\t\t\t\tate[i] = theta[1]\n",
    "\telif datatype == 'discrete':\n",
    "\t\terror('not implemented')\n",
    "\telse:\n",
    "\t\terror('no such datatype')\n",
    "\n",
    "\treturn ate\n",
    "\n",
    "\n",
    "# code inspired by algorithm_applyRules123_random.m\n",
    "# NOTE from entner!\n",
    "# NOTE: in the comments of the code, the rule numbers do not match the ones in\n",
    "      # the paper. (We changed themw later on in the article, apologies for any \n",
    "      # inconveniences.) Here is the correspondence between the rules:\n",
    "\n",
    "      # article               code\n",
    "      # R1 (i) + (ii)         R3 (iii) + (ii) (Note R3(i) in code is not used)\n",
    "      # R2 (i)                R1\n",
    "      # R2 (ii) + (iii)       R2\n",
    "# INPUT\n",
    "# data\n",
    "# D (n,d+3)... data matrix\n",
    "#   (n,d)  ... Z covariates\n",
    "#   (n,)   ... W auxiliary variable\n",
    "#   (n,)   ... X treatment\n",
    "#   (n,)   ... Y outcome\n",
    "# datatype ... string: 'continuous' if data are Gaussain\n",
    "#                      'discrete' if data are discrete\n",
    "# k        ... maximal size of conditioning set in independence test\n",
    "# t        ... how many tests are performed, i.e. how often do we\n",
    "#                     select a random set Z (and w) and perform test\n",
    "# \n",
    "# OUTPUT\n",
    "# p_vals ... p-values from tests\n",
    "# Zsels  ... selected Zs\n",
    "def Zsel_highdim(D, datatype, k, t):\n",
    "\n",
    "\t(n,d3) = D.shape\n",
    "\tixY    = d3-1\n",
    "\tixX    = d3-2\n",
    "\tixW    = d3-3\n",
    "\tixZ    = np.arange(d3-3)\n",
    "\td      = d3-3\n",
    "\n",
    "\tif datatype == 'continuous':\n",
    "\t\titest = 'partialCorr'\n",
    "\t\tcov = np.cov(D.transpose())\n",
    "\telif datatype == 'discrete':\n",
    "\t\titest = 'logOdds'\n",
    "\t\tcov = D\n",
    "\telse:\n",
    "        error('no such datatype')\n",
    "\n",
    "\tn_R3_cardZ = np.zeros((k+1,1)) # how many sets of each conditioning size up to K\n",
    "\tfor i in range(k+1):\n",
    "\t\tn_R3_cardZ[i] = comb(d,i)\n",
    "\n",
    "\t# cumulative proportions of conditioing sets of size 0,...,K, for one w\n",
    "\tcumprop_R3 =  np.cumsum(n_R3_cardZ) / np.sum(n_R3_cardZ); \n",
    "\n",
    "\n",
    "\t# save things\n",
    "\tZsels = []\n",
    "\tp_vals_wy_zx = np.zeros((t,))\n",
    "\tp_vals_wy_z  = np.zeros((t,))\n",
    "\n",
    "\trand_r = np.random.random(size=t)\n",
    "\tfor i in range(t):\n",
    "\t\t#w = rand_d[i]\n",
    "\t\tr   = rand_r[i]\n",
    "\t\tcardZ = np.argmin(cumprop_R3 < r) # find the sampled bin\n",
    "\t\t#Ww = np.setdiff1d(W,w)\n",
    "\t\ttemp = np.random.permutation(d)\n",
    "\t\tix_Zsel = np.sort(temp[:cardZ])\n",
    "\n",
    "\t\t# condition 2 of R3: w indep y given Z and x\n",
    "\t\tpval_wy_ZX_R3 = indepTest(ixW, ixY, np.append(ix_Zsel,ixX), n, cov, itest);\n",
    "        \n",
    "\t\t# condition 3 of R3: w not indep y given Z\n",
    "\t\tpval_wy_Z_R3 = indepTest(ixW, ixY, ix_Zsel, n, cov, itest);\n",
    "\n",
    "\t\tp_vals_wy_zx[i] = pval_wy_ZX_R3\n",
    "\t\tp_vals_wy_z[i]  = pval_wy_Z_R3\n",
    "\t\tZsels.append(ix_Zsel)\n",
    "\treturn p_vals_wy_zx, p_vals_wy_z, Zsels\n",
    "\n",
    "\n",
    "\n",
    "def indepTest(ixA, ixB, ixZ, n, C, itest):\n",
    "\tif itest == 'partialCorr':\n",
    "\t\tixAB = np.array([ixA,ixB])\n",
    "\t\t#        C(indAB,indAB) - C(indAB,ixZ) * C(ixZ,ixZ)^(-1) * C(ixZ,indAB)\n",
    "\t\tC_cond = C[ixAB,:][:,ixAB] - np.dot(C[ixAB,:][:,ixZ], np.linalg.solve(C[ixZ,:][:,ixZ], C[ixZ,:][:,ixAB]))\n",
    "\t\t# test if partial correlation is statistically significantly different\n",
    "\t\t# from 0 (using Fisher's Z, see Spirtes et al. p.94); if not, independence\n",
    "\t\tr = C_cond[0,1]\n",
    "\t\tfisherZ = 0.5* np.sqrt(n - ixZ.shape[0] - 3) * np.log(np.abs(1+r) / np.abs(1-r));\n",
    "\t\tp = 2*(1-norm.cdf(np.abs(fisherZ)));\n",
    "\telif itest == 'logOdds':\n",
    "\t\terror('not implemented yet')\n",
    "\t\t#[pval_g, pval_chi] = gsquare_test(DataCov,states,w,x,Z);\n",
    "\t\t#p = pval_g;\n",
    "\treturn p\n",
    "\n",
    "# NOTE: DON'T USE THIS, JUST FOR TESTING\n",
    "def depricated_sampling(n):\n",
    "\tz_dim = 30\n",
    "\tu_dim = 30\n",
    "\ta,b,c,d,e,l = np.random.normal(0,1,6)\n",
    "\tf,g,h,j,k = np.random.normal(0,1,size=(5,z_dim))\n",
    "\n",
    "\tD = np.zeros((n,z_dim*4+3))\n",
    "\tfor i in range(n):\n",
    "\t\tW  = np.random.normal(0,1)\n",
    "\t\tU1 = np.random.normal(0,1,u_dim)\n",
    "\t\tU2 = np.random.normal(0,1,u_dim)\n",
    "\t\tZ1 = a*U1 + b*U2 + c*W + np.random.normal(0,.5,z_dim)\n",
    "\t\tZ2 = d*W  + np.random.normal(0,.5,z_dim)\n",
    "\t\tZ3 = np.random.normal(0,1,z_dim)\n",
    "\t\tZ4 = np.random.normal(0,1,z_dim)\n",
    "\t\tX = e*W + np.dot(f,U1) + np.dot(g,Z2) + np.dot(h,Z3) + np.random.normal(0,.5)\n",
    "\t\tY = np.dot(j,Z3) + np.dot(k,Z4) + l*X + np.random.normal(0,.5)\n",
    "\t\tD[i,:z_dim] = Z1\n",
    "\t\tD[i,z_dim:z_dim*2] = Z2\n",
    "\t\tD[i,z_dim*2:z_dim*3] = Z3\n",
    "\t\tD[i,z_dim*3:z_dim*4] = Z4\n",
    "\t\tD[i,z_dim*4] = W\n",
    "\t\tD[i,z_dim*4+1] = X\n",
    "\t\tD[i,z_dim*4+2] = Y\n",
    "\treturn D, l\n",
    "\n",
    "\n",
    "def run(D):\n",
    "    datatype = 'continuous' # they only have code for continuous data\n",
    "    k = 30   # maximal size of conditioning set (Z3 is true set)\n",
    "    t = 1000 # tests\n",
    "    p_vals_wy_zx, p_vals_wy_z, Zsels = Zsel_highdim(D, datatype, k, t)\n",
    "    ate = estimate_effects(D, datatype, p_vals_wy_zx, p_vals_wy_z, Zsels)\n",
    "    print(\"ate:\")\n",
    "    print(ate)\n",
    "    return ate, np.median(ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_D = []\n",
    "# train_ATE_errs = []\n",
    "# valid_ATE_errs = []\n",
    "# # for i in range(1,21):\n",
    "#     with open('Entner/eta_nomralize_hard_allZ_Oct2/outputfiles/train_data_'+str(i)+'.pickle', 'rb') as pickle_file:\n",
    "#         train_D = pickle.load(pickle_file)\n",
    "#     with open('Entner/eta_nomralize_hard_allZ_Oct2/outputfiles/valid_data_'+str(i)+'.pickle', 'rb') as pickle_file:\n",
    "#         valid_D = pickle.load(pickle_file)\n",
    "#     with open('Entner/eta_nomralize_hard_allZ_Oct2/outputfiles/train_real_ATE_'+str(i)+'.pickle', 'rb') as pickle_file:\n",
    "#         l_train = pickle.load(pickle_file)\n",
    "#     with open('Entner/eta_nomralize_hard_allZ_Oct2/outputfiles/valid_real_ATE_'+str(i)+'.pickle', 'rb') as pickle_file:\n",
    "#         l_valid = pickle.load(pickle_file)\n",
    "\n",
    "split = trunc(Int,(size(dat)[1]/2))\n",
    "dat_train = dat[1:split,:]\n",
    "dat_valid = dat[split+1:end,:]\n",
    "\n",
    "ate_all_train, ate_median_train = run(dat_train)\n",
    "ate_all_valid, ate_median_valid = run(dat_valid)\n",
    "err_train = np.abs(ate_median_train - l_train)\n",
    "err_valid = np.abs(ate_median_valid - l_valid)\n",
    "# train_ATE_errs.append(err_train)\n",
    "# valid_ATE_errs.append(err_valid)\n",
    "err_train, err_valid\n",
    "\n",
    "# pickle.dump( train_ATE_errs, open( \"train_ATE_errs.p\", \"wb\" ) )\n",
    "# pickle.dump( valid_ATE_errs, open( \"valid_ATE_errs.p\", \"wb\" ) )\n",
    "# print(\"mean train ATE err: \" + str(np.mean(train_ATE_errs)))\n",
    "# print(\"mean valid ATE err: \" + str(np.mean(valid_ATE_errs)))\n",
    "#     print('ate err = ' + str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choose_lambdas (generic function with 2 methods)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function choose_lambdas(lambda_twos, lambda1, seeds, dat, vertex_labels, max_iter, lrs, corr_boost, path_to_file)\n",
    "  initial_lambda1 = lambda1\n",
    "  corr_pxs = Dict() \n",
    "  hypo_fail_all_lambdas = Dict()\n",
    "  num_Z = length(vertex_labels.z1)+length(vertex_labels.z3)\n",
    "#   ATE_results_test = nothing\n",
    "\n",
    "\n",
    "  w, x, y = vertex_labels.w, vertex_labels.x, vertex_labels.y\n",
    "  Z = [vertex_labels.z1; vertex_labels.z3]\n",
    "  best_Z = vertex_labels.z3\n",
    "\n",
    "  split = trunc(Int,(size(dat)[1]/3))\n",
    "  dat_train = dat[1:split,:]\n",
    "  dat_valid = dat[split+1:split*2,:]\n",
    "  dat_test = dat[(split*2)+1:end,:]\n",
    "  # Sigma train construction\n",
    "  Sigma_hat = cov(dat_train)\n",
    " for seed in seeds\n",
    "    Random.seed!(seed);\n",
    "  for lambda2 in lambda_twos\n",
    "    println(\"lambda2: \", lambda2)\n",
    "    for lr in lrs\n",
    "      hypo_fail = Dict()\n",
    "      println(\"lr: \", lr)\n",
    "      reject_null_hypothesis = false\n",
    "      lambda1 = initial_lambda1\n",
    "      bonferonni_correction = 1.\n",
    "      while (!reject_null_hypothesis)\n",
    "\n",
    "        # learn theta on training set\n",
    "        theta_hat, corr_px_theta_hat, corr_p_theta_hat = \n",
    "            bd_learn_linear(Sigma_hat, lambda1, lambda2, vertex_labels, 1, path_to_file,\n",
    "                                    max_iter = max_iter, lr = lr, corr_boost = corr_boost)\n",
    "\n",
    "        thresh = 1e-3\n",
    "        sel_Z = findall(x->abs(x)>thresh, theta_hat)\n",
    "        sel_Z = [x+Z[1]-1 for x in sel_Z]\n",
    "        println(sel_Z)\n",
    "        # test for the null hypothesis\n",
    "        reject_null_hypothesis = \n",
    "          ind_null_hypo(n, num_Z, corr_p_theta_hat; significance_level=(0.01/bonferonni_correction))\n",
    "        # if null rejected, i.e. reject_null_hypothesis=true\n",
    "        if reject_null_hypothesis\n",
    "          # compute ATEs training set\n",
    "          Sigma_wyx_phi = build_phi_covariance(theta_hat, w, y, x, Z, Sigma_hat)\n",
    "        try   \n",
    "          atr_real_train = 0.\n",
    "          ate_hat_train = (Sigma_wyx_phi[[3; 4], [3; 4]] \\ Sigma_wyx_phi[[3; 4], 2])[1]\n",
    "          ate_hat_all_Z_train = (Sigma_hat[[x; Z], [x; Z]] \\ Sigma_hat[[x; Z], y])[1]\n",
    "          ate_hat_best_Z_train = (Sigma_hat[[x; best_Z], [x; best_Z]] \\ Sigma_hat[[x; best_Z], y])[1]\n",
    "          ate_hat_sel_Z_train = (Sigma_hat[[x; sel_Z], [x; sel_Z]] \\ Sigma_hat[[x; sel_Z], y])[1]\n",
    "          ate_hat_marg_Z_train = Sigma_hat[x, y] / Sigma_hat[x, x]\n",
    "\n",
    "          ATE_results_train = [atr_real_train ate_hat_best_Z_train ate_hat_train ate_hat_all_Z_train ate_hat_sel_Z_train ate_hat_marg_Z_train]\n",
    "          # ATE_results_train = [ate_hat_best_Z_train ate_hat_train ate_hat_all_Z_train ate_hat_sel_Z_train ate_hat_marg_Z_train]\n",
    "\n",
    "          # compute \\rho(W,Y|beta*Z, X) validation\n",
    "          Sigma_hat_valid = cov(dat_valid)\n",
    "          Sigma_wyx_phi_valid = build_phi_covariance(theta_hat, w, \n",
    "            x, y, Z, Sigma_hat_valid)\n",
    "   \n",
    "            corr_px_valid = abs(partial_corr([1; 2], [3; 4], Sigma_wyx_phi_valid)[1, 2])\n",
    "            # compute ATEs validation set\n",
    "            atr_real_valid = 0.\n",
    "            ate_hat_valid = (Sigma_wyx_phi_valid[[3; 4], [3; 4]] \\ Sigma_wyx_phi_valid[[3; 4], 2])[1]\n",
    "            ate_hat_all_Z_valid = (Sigma_hat_valid[[x; Z], [x; Z]] \\ Sigma_hat_valid[[x; Z], y])[1]\n",
    "            ate_hat_best_Z_valid = (Sigma_hat_valid[[x; best_Z], [x; best_Z]] \\ Sigma_hat_valid[[x; best_Z], y])[1]\n",
    "            ate_hat_sel_Z_valid = (Sigma_hat_valid[[x; sel_Z], [x; sel_Z]] \\ Sigma_hat_valid[[x; sel_Z], y])[1]\n",
    "            println(ate_hat_sel_Z_valid)\n",
    "            ate_hat_marg_Z_valid = Sigma_hat_valid[x, y] / Sigma_hat_valid[x, x]\n",
    "\n",
    "            ATE_results_valid = [atr_real_valid ate_hat_best_Z_valid ate_hat_valid ate_hat_all_Z_valid ate_hat_sel_Z_valid ate_hat_marg_Z_valid]\n",
    "            # ATE_results_valid = [ate_hat_best_Z_valid ate_hat_valid ate_hat_all_Z_valid ate_hat_sel_Z_valid ate_hat_marg_Z_valid]\n",
    "            # save corrs\n",
    "            hypo_fail[\"seed\"] = seed\n",
    "            hypo_fail[\"corr_px_train\"] = corr_px_theta_hat\n",
    "            hypo_fail[\"corr_p_train\"] = corr_p_theta_hat\n",
    "            hypo_fail[\"corr_px_valid\"] = corr_px_valid\n",
    "            hypo_fail[\"lr\"] = lr\n",
    "            # parameters\n",
    "            hypo_fail[\"theta_hat\"] = theta_hat\n",
    "            hypo_fail[\"sel_Z\"] = sel_Z\n",
    "            hypo_fail[\"lambda1\"] = lambda1\n",
    "            hypo_fail[\"lambda2\"] = lambda2\n",
    "            # ATEs train\n",
    "            hypo_fail[\"ATE_results_train\"] = ATE_results_train\n",
    "            # ATEs valid\n",
    "            hypo_fail[\"ATE_results_valid\"] = ATE_results_valid\n",
    "            hypo_fail_all_lambdas[hypo_fail[\"corr_px_valid\"]] = hypo_fail\n",
    "            break\n",
    "          catch\n",
    "            lambda1 = lambda1 * 2\n",
    "            bonferonni_correction += 1.\n",
    "          end\n",
    "        else\n",
    "          lambda1 = lambda1 * 2\n",
    "          bonferonni_correction += 1.\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "  end\n",
    " end\n",
    "  best_setup = hypo_fail_all_lambdas[minimum(keys(hypo_fail_all_lambdas))]\n",
    "    Sigma_hat_test = cov(dat_test)\n",
    "    Sigma_wyx_phi_test = build_phi_covariance(best_setup[\"theta_hat\"], w, \n",
    "    x, y, Z, Sigma_hat_test)\n",
    "    # compute ATEs test set\n",
    "    atr_real_test = 0.\n",
    "    ate_hat_test = (Sigma_wyx_phi_test[[3; 4], [3; 4]] \\ Sigma_wyx_phi_test[[3; 4], 2])[1]\n",
    "    ate_hat_all_Z_test = (Sigma_hat_test[[x; Z], [x; Z]] \\ Sigma_hat_test[[x; Z], y])[1]\n",
    "    ate_hat_best_Z_test = (Sigma_hat_test[[x; best_Z], [x; best_Z]] \\ Sigma_hat_test[[x; best_Z], y])[1]\n",
    "    ate_hat_sel_Z_test = (Sigma_hat_test[[x; best_setup[\"sel_Z\"]], [x; best_setup[\"sel_Z\"]]] \\ Sigma_hat_test[[x; best_setup[\"sel_Z\"]], y])[1]\n",
    "\n",
    "    println(ate_hat_sel_Z_test)\n",
    "    ate_hat_marg_Z_test = Sigma_hat_test[x, y] / Sigma_hat_test[x, x]\n",
    "\n",
    "    ATE_results_test = [atr_real_test ate_hat_best_Z_test ate_hat_test ate_hat_all_Z_test ate_hat_sel_Z_test ate_hat_marg_Z_test]\n",
    "  return best_setup, ATE_results_test\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHS data, smaller var, Oct 8 morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_small_var = zeros(90000, num_vertices);\n",
    "m = 1\n",
    "for row in CSV.Rows(\"nhs_data_smaller_var.csv\", datarow=2)\n",
    "    dat_small_var[m,:] = [parse(Float64, x) for x in row[2:end]]\n",
    "    m+=1\n",
    "end\n",
    "\n",
    "\n",
    "# dat_small_var = dat_small_var[30001:end,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda2: 1.0\n",
      "lr: 5.0e-5\n",
      "[14, 15, 20, 21, 22, 23, 24]\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "-0.1023688604165896\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lambda2: 0.1\n",
      "lr: 5.0e-5\n",
      "[14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.2782191850887803\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0005\n",
      "[14, 17, 19, 20, 23, 24]\n",
      "1.7297420094903093\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 18, 19, 21, 22, 23, 24, 25]\n",
      "2.174676862327235\n",
      "lambda2: 0.01\n",
      "lr: 5.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lambda2: 1.0\n",
      "lr: 5.0e-5\n",
      "[16, 17, 20, 21, 23, 24]\n",
      "[15, 16, 18, 19, 20, 22, 23, 24]\n",
      "1.8964058892410345\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lambda2: 0.1\n",
      "lr: 5.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25]\n",
      "0.9396252874616292\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0005\n",
      "[15, 16, 17, 18, 19, 21, 22, 23, 24, 25]\n",
      "2.1747407292502903\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lambda2: 0.01\n",
      "lr: 5.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0005\n",
      "[14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.4718248757596631\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lambda2: 1.0\n",
      "lr: 5.0e-5\n",
      "[15, 17, 20, 21, 24]\n",
      "3.0060749059062446\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 18, 19, 22, 23, 25]\n",
      "1.813102885621421\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lambda2: 0.1\n",
      "lr: 5.0e-5\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0005\n",
      "[14, 15, 18, 19, 21, 23, 24, 25]\n",
      "1.5073300622442853\n",
      "lr: 0.0002\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 18, 19, 21, 22, 24]\n",
      "1.717348259358822\n",
      "lambda2: 0.01\n",
      "lr: 5.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 2.0e-5\n",
      "[14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.2933043501035435\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.27396984822314113\n",
      "-0.12664746354762166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dict{Any,Any}(\"lr\"=>5.0e-5,\"ATE_results_valid\"=>[0.0 0.0363165 … -0.102369 1.77332],\"ATE_results_train\"=>[0.0 0.0361244 … -0.118334 1.78158],\"sel_Z\"=>[15, 16, 17, 18, 19, 20, 21, 22, 23],\"lambda2\"=>1.0,\"lambda1\"=>0.001,\"corr_px_valid\"=>0.591291,\"theta_hat\"=>[-3.67275e-6, 0.545617, 0.0533428, -0.0195926, 0.289827, -0.0824615, -0.184364, -0.0281681, -0.0421756, 0.307724, -6.32423e-5, 5.01771e-5],\"seed\"=>20,\"corr_p_train\"=>0.115755…), [0.0 0.0364751 … -0.126647 1.78344])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda1=5e-4\n",
    "# lrs=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3]\n",
    "# lambda_twos=[5, 2, 1]\n",
    "# lrs=[1e-4, 1e-5, 2e-5]\n",
    "lambda_twos=[1, 1e-1, 1e-2]\n",
    "lrs=[5e-5, 2e-5, 5e-4, 2e-4]\n",
    "seeds = [20, 40, 60]\n",
    "max_iter = 1000\n",
    "corr_boost=1\n",
    "best_setup, ATEs = choose_lambdas(lambda_twos, lambda1, seeds, dat_small_var, vertex_labels, max_iter, lrs, corr_boost, \"Continuous_revival/real_world/outputfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.0e-5, 1.0)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setup[\"lr\"],best_setup[\"lambda2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Array{Float64,2}:\n",
       " 0.0  0.0363165  0.331118  -0.27397  -0.102369  1.77332"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setup[\"ATE_results_valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Array{Float64,2}:\n",
       " 0.0  0.0364751  0.333002  -0.287561  -0.126647  1.78344"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03613994943765849"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATEs_results = []\n",
    "append!(ATEs_results, best_setup[\"ATE_results_valid\"])\n",
    "append!(ATEs_results, 0.0045665072676280725)\n",
    "ATEs_results[1] = 0.03613994943765849"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.29)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(abs(ATEs_results[1] - ATEs_results[5]),digits=3), round(abs(ATEs_results[1] - ATEs_results[4]), digits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.734, 0.032)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(abs(ATEs_results[1] - ATEs_results[6]), digits=3), round(abs(ATEs_results[1] -ATEs_results[7]),digits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATE_learned"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"simulate.jl\")\n",
    "include(\"learn_linear.jl\")\n",
    "include(\"util.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda2: 1.0\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 22, 23, 25]\n",
      "1.7400403937527105\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.0022963116679162936\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lambda2: 0.5\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25]\n",
      "1.8421010368924406\n",
      "lr: 0.0002\n",
      "[14, 17, 18, 19, 20, 21, 23]\n",
      "0.6958866133738458\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lambda2: 0.1\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.002\n",
      "[20]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 10 entries:\n",
       "  \"lambda1\"           => 0.001\n",
       "  \"ATE_results_train\" => [0.0 0.0360363 … 0.00154426 1.77702]\n",
       "  \"lr\"                => 0.0002\n",
       "  \"corr_px_valid\"     => 0.053125\n",
       "  \"sel_Z\"             => [14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25]\n",
       "  \"theta_hat\"         => [-0.00865563, -0.00246184, 4.69253, -0.00088393, -0.00…\n",
       "  \"corr_p_train\"      => 0.0171644\n",
       "  \"corr_px_train\"     => 0.0585722\n",
       "  \"ATE_results_valid\" => [0.0 0.0358647 … -0.00229631 1.77063]\n",
       "  \"lambda2\"           => 1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda_twos=[2, 2e-2, 1e-2, 2e-3]\n",
    "# lambda_twos=[5, 2, 1, 5e-1, 2e-1, 1e-1]\n",
    "lambda1=5e-4\n",
    "# lrs=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3]\n",
    "lambda_twos=[1, 5e-1, 1e-1]\n",
    "lrs=[2e-5, 2e-4, 2e-3]\n",
    "max_iter = 1000\n",
    "corr_boost=1\n",
    "best_setup = choose_lambdas(lambda_twos, lambda1, dat, vertex_labels, max_iter, lrs, corr_boost, \"Continuous_revival/real_world/outputfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: extra token \"ATE\" after end of expression",
     "output_type": "error",
     "traceback": [
      "syntax: extra token \"ATE\" after end of expression",
      ""
     ]
    }
   ],
   "source": [
    "# true=0.03617257959085344\n",
    "# marg=-0.007099066432687132\n",
    "# allZ=1.7737528049169522\n",
    "# usingZ3=0.03596626017737463\n",
    "\n",
    "# true: 0.03617257959085344\n",
    "# marg: 1.77104284\n",
    "# allZ: -0.009096044633038352\n",
    "# usingZ3: 0.03565197301862628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Array{Float64,2}:\n",
       " 0.0  0.0358647  0.296284  -0.00882631  -0.00229631  1.77063"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setup[\"ATE_results_valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Array{Int64,1}:\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23\n",
       " 24\n",
       " 25"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setup[\"sel_Z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Array{Float64,2}:\n",
       " 0.0  0.0358647  0.296284  -0.00882631  -0.00229631  1.77063"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATEs =  [0.03617257959085344  0.0358647  0.296284  -0.00882631  -0.00229631  1.77063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00229631, 0.00882631, 1.77063)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(ATEs[1] - ATEs[5]), abs(ATEs[1] - ATEs[4]), abs(ATEs[1] - ATEs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002190385869365213"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entner = (-0.0002190385869365213)\n",
    "abs(ATEs[1] - Entner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda2: 5.0\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25]\n",
      "1.8421010368924406\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.02\n",
      "[14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lambda2: 1.0\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 19, 22, 24, 25]\n",
      "[14, 15, 17, 18, 19, 20, 21, 23, 24, 25]\n",
      "0.8474957109508536\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.02\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.00834427128540468\n",
      "lambda2: 0.5\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 23, 24, 25]\n",
      "1.681045797318564\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.02\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lambda2: 0.1\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n",
      "lr: 0.0005\n",
      "[15, 16, 17, 19, 20, 21, 22, 23, 24]\n",
      "3.6584950725539898\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.009222228559045302\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25]\n",
      "2.0884787338515496\n",
      "lr: 0.02\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "-0.008826311329718844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 10 entries:\n",
       "  \"lambda1\"           => 0.0005\n",
       "  \"ATE_results_train\" => [0.0 0.0360363 … -0.00533642 1.77702]\n",
       "  \"lr\"                => 0.0002\n",
       "  \"corr_px_valid\"     => 0.234749\n",
       "  \"sel_Z\"             => [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
       "  \"theta_hat\"         => [0.0134578, -0.00650186, -0.00957617, 6.40321, 0.01228…\n",
       "  \"corr_p_train\"      => 0.525858\n",
       "  \"corr_px_train\"     => 0.0179708\n",
       "  \"ATE_results_valid\" => [0.0 0.0358647 … -0.00882631 1.77063]\n",
       "  \"lambda2\"           => 0.5"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda_twos=[2, 2e-2, 1e-2, 2e-3]\n",
    "# lambda_twos=[5, 2, 1, 5e-1, 2e-1, 1e-1]\n",
    "lambda1=5e-4\n",
    "# lrs=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3]\n",
    "lambda_twos=[5, 1, 5e-1, 1e-1]\n",
    "lrs=[2e-5, 5e-4, 2e-4, 2e-3, 2e-2]\n",
    "max_iter = 1000\n",
    "corr_boost=1\n",
    "best_setup = choose_lambdas(lambda_twos, lambda1, dat, vertex_labels, max_iter, lrs, corr_boost, \"Continuous_revival/real_world/outputfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04539480814989874, 0.044998889590853436)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.03617257959085344+0.009222228559045302, 0.03617257959085344+0.00882631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Array{Float64,2}:\n",
       " 0.0  0.0358647  0.522219  -0.00882631  -0.00882631  1.77063"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setup[\"ATE_results_valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{Int64,1}:\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23\n",
       " 24\n",
       " 25"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_setup[\"sel_Z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oct 8 NHS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_oct8 = zeros(30000, num_vertices);\n",
    "j = 1\n",
    "for row in CSV.Rows(\"nhs_data_test_Oct8.csv\", datarow=2)\n",
    "    dat_oct8[j,:] = [parse(Float64, x) for x in row[2:end]]\n",
    "    j+=1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda2: 5.0\n",
      "lr: 2.0e-5\n",
      "[16, 19, 21, 25]\n",
      "1.1527161722404462\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.02\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lambda2: 1.0\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 23]\n",
      "1.7000364451816394\n",
      "lr: 0.0005\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.0002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.02\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lambda2: 0.5\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.0005\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.025632568766664712\n",
      "lr: 0.0002\n",
      "[17, 21, 23, 25]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.02\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lambda2: 0.1\n",
      "lr: 2.0e-5\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.0005\n",
      "[14, 18, 19, 21, 23, 24]\n",
      "1.5669104376487182\n",
      "lr: 0.0002\n",
      "[15, 16, 17, 18, 19, 21, 22, 23, 24, 25]\n",
      "2.1025626601557295\n",
      "lr: 0.002\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n",
      "lr: 0.02\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "0.013730131020688735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 10 entries:\n",
       "  \"lambda1\"           => 0.0005\n",
       "  \"ATE_results_train\" => [0.0 0.0359246 … 0.0127483 1.76117]\n",
       "  \"lr\"                => 0.0005\n",
       "  \"corr_px_valid\"     => 0.338511\n",
       "  \"sel_Z\"             => [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
       "  \"theta_hat\"         => [-0.00093249, 6.20858, -0.02681, 0.0233086, 0.0364292,…\n",
       "  \"corr_p_train\"      => 0.494082\n",
       "  \"corr_px_train\"     => 0.00134359\n",
       "  \"ATE_results_valid\" => [0.0 0.036167 … 0.0256326 1.76145]\n",
       "  \"lambda2\"           => 0.5"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching complete_type(::String)\nClosest candidates are:\n  complete_type(!Matched::Type{#s68} where #s68<:Function) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/handlers.jl:54\n  complete_type(!Matched::Type{#s68} where #s68<:Type) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/handlers.jl:55\n  complete_type(!Matched::Type{#s68} where #s68<:Tuple) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/handlers.jl:56\n  ...",
     "output_type": "error",
     "traceback": [
      "KERNEL EXCEPTION",
      "MethodError: no method matching complete_type(::String)\nClosest candidates are:\n  complete_type(!Matched::Type{#s68} where #s68<:Function) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/handlers.jl:54\n  complete_type(!Matched::Type{#s68} where #s68<:Type) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/handlers.jl:55\n  complete_type(!Matched::Type{#s68} where #s68<:Tuple) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/handlers.jl:56\n  ...",
      "",
      "Stacktrace:",
      " [1] complete_types(::Array{String,1}) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/handlers.jl:100",
      " [2] complete_request(::ZMQ.Socket, ::IJulia.Msg) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/handlers.jl:139",
      " [3] #invokelatest#1 at ./essentials.jl:742 [inlined]",
      " [4] invokelatest at ./essentials.jl:741 [inlined]",
      " [5] eventloop(::ZMQ.Socket) at /Users/Limor/.julia/packages/IJulia/gI2uA/src/eventloop.jl:8",
      " [6] (::getfield(IJulia, Symbol(\"##15#18\")))() at ./task.jl:259"
     ]
    }
   ],
   "source": [
    "lambda1=5e-4\n",
    "# lrs=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3]\n",
    "lambda_twos=[5, 1, 5e-1, 1e-1]\n",
    "lrs=[2e-5, 5e-4, 2e-4, 2e-3, 2e-2]\n",
    "max_iter = 1000\n",
    "corr_boost=1\n",
    "best_setup = choose_lambdas(lambda_twos, lambda1, dat_oct8, vertex_labels, max_iter, lrs, corr_boost, \"Continuous_revival/real_world/outputfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03613994943765849"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATEs_oct8 = []\n",
    "append!(ATEs_oct8, best_setup[\"ATE_results_valid\"])\n",
    "append!(ATEs_oct8, 0.0045665072676280725)\n",
    "ATEs_oct8[1] = 0.03613994943765849"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013730131020688735"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATEs_oct8[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.011, 0.022)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(abs(ATEs_oct8[1] - ATEs_oct8[5]),digits=3), round(abs(ATEs_oct8[1] - ATEs_oct8[4]), digits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.725, 0.032)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(abs(ATEs_oct8[1] - ATEs_oct8[6]), digits=3), round(abs(ATEs_oct8[1] -ATEs_oct8[7]),digits=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
